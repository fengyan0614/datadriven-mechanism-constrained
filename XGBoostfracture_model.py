import numpy as np
import pandas as pd
import xgboost as xgb
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import warnings
import sys

warnings.filterwarnings('ignore')

"""
æ ¸å¿ƒä¿®å¤ç‚¹ï¼ˆå¯¼è‡´â€œæ ¡æ­£åŒºé—´å…¨éƒ½ä¸€æ ·â€çš„åŸå›  & è§£å†³åŠæ³•ï¼‰
1) æ—§ç‰ˆä»…ç”¨å¸¸é‡å ä½ç‰¹å¾ X=1ï¼Œæ ‘æ— æ³•åˆ†è£‚ â†’ åªæœ‰ä¸€ä¸ªå¶å­ â†’ å…¨æ ·æœ¬é¢„æµ‹ç›¸åŒã€‚
   âœ… ç°åœ¨å°† (a) n_smoothed æœ¬èº«ã€(b) mode çš„ one-hot ä½œä¸ºç‰¹å¾ï¼Œ
      ä½¿æ¨¡å‹èƒ½å¯¹ä¸åŒæ¨¡å¼ã€ä¸åŒæ ·æœ¬å­¦ä¹ â€œæ ¡æ­£åç§»â€ã€‚
2) å…¨å±€ç‰©ç†å¼•å¯¼é¡¹ä½¿ç”¨ (y_pred - mean(y_pred))ï¼Œåœ¨å•å¶åœºæ™¯ä¼šè¢«æŠµæ¶ˆã€‚
   âœ… ç°åœ¨æ”¹ä¸ºæ¯ä¸ªæ ·æœ¬ç›´æ¥æ–½åŠ æ–¹å‘æ€§â€œæ¨åŠ›â€ï¼ˆå¸¸æ•°æ¢¯åº¦åç½®ï¼‰ï¼Œ
      ä¸ event_srv_ratio / length_height_ratio / fracture_height æ­£ç›¸å…³ï¼Œ
      ä½¿ mode 2/3/4 æ–¹å‘ä¸Šæ›´å®¹æ˜“â€œæŠ¬å‡â€é¢„æµ‹ï¼›mode 1 è½»å¾®â€œå‹ä½â€ã€‚
3) è®­ç»ƒæ—¶å¼•å…¥ sample_weightï¼ˆæŒ‰å…¨å±€å¾®åœ°éœ‡ç‰¹å¾ä¸ºä¸åŒæ¨¡å¼æ ·æœ¬åŠ æƒï¼‰ï¼Œ
   è®©ä¸â€œå…¨å±€çº¦æŸâ€ä¸€è‡´çš„æ¨¡å¼æ ·æœ¬æƒé‡æ›´å¤§ï¼Œä»è€Œä¸»åŠ¨â€œé æ‹¢â€å¾®åœ°éœ‡ã€‚

ä½¿ç”¨æ–¹å¼ï¼š
python XGBoostfracture_model_fixed.py path_to_excel.xlsx
Excel è‡³å°‘åŒ…å«åˆ—ï¼ševent_srv_ratio, length_height_ratio, fracture_height, n_smoothed, mode
"""

# -------------------------------
# å…¨å±€ç¼“å­˜ï¼ˆç”¨äºè‡ªå®šä¹‰æŸå¤±è®¿é—®ï¼‰
# -------------------------------
TRAIN_CONSTRAINTS = None
TEST_CONSTRAINTS = None
GLOBAL_EVENT = None
GLOBAL_LENGTH_RATIO = None
GLOBAL_HEIGHT = None


# -------------------------------
# 1) æ•°æ®åŠ è½½ä¸æ ¡éªŒ
# -------------------------------
def load_data(excel_path: str) -> pd.DataFrame:
    df = pd.read_excel(excel_path)
    required = ['event_srv_ratio', 'length_height_ratio', 'fracture_height', 'n_smoothed', 'mode']
    miss = [c for c in required if c not in df.columns]
    if miss:
        raise ValueError(f"æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {miss}")

    # å…³é”®ä¿®å¤ï¼šå…ˆæå–å…¨å±€å˜é‡ï¼ˆåŸºäºåŸå§‹æ•°æ®ï¼ŒåŒ…å«æ‰€æœ‰modeï¼‰
    global GLOBAL_EVENT, GLOBAL_LENGTH_RATIO, GLOBAL_HEIGHT
    GLOBAL_EVENT = df['event_srv_ratio'].dropna().unique()
    GLOBAL_LENGTH_RATIO = df['length_height_ratio'].dropna().unique()
    GLOBAL_HEIGHT = df['fracture_height'].dropna().unique()
    # æ ¡éªŒå…¨å±€å˜é‡æ˜¯å¦ä¸ºå•å€¼
    if len(GLOBAL_EVENT) != 1 or len(GLOBAL_LENGTH_RATIO) != 1 or len(GLOBAL_HEIGHT) != 1:
        raise ValueError('event_srv_ratio / length_height_ratio / fracture_height åº”ä¸ºæ•´æ®µå•å€¼')
    GLOBAL_EVENT = float(GLOBAL_EVENT[0])
    GLOBAL_LENGTH_RATIO = float(GLOBAL_LENGTH_RATIO[0])
    GLOBAL_HEIGHT = float(GLOBAL_HEIGHT[0])
    print("\nğŸ“Œ å…¨å±€å¾®åœ°éœ‡çº¦æŸ:")
    print(f"  event_srv_ratio = {GLOBAL_EVENT}")
    print(f"  length_height_ratio = {GLOBAL_LENGTH_RATIO}")
    print(f"  fracture_height = {GLOBAL_HEIGHT}")

    # å†è¿‡æ»¤modeï¼ˆåªä¿ç•™1-4ï¼‰
    df = df[df['mode'].isin([1, 2, 3, 4])].copy()
    df['mode'] = df['mode'].astype(int)

    # n_smoothed æ¸…æ´—ï¼ˆä¸å˜ï¼‰
    if df['n_smoothed'].isna().any():
        df['n_smoothed'].fillna(df['n_smoothed'].mean(), inplace=True)
    if np.isinf(df['n_smoothed']).any():
        raise ValueError('n_smoothed å­˜åœ¨æ— ç©·å¤§ï¼Œè¯·å…ˆæ¸…æ´—')

    return df


# -------------------------------
# 2) æ„å»ºç‰¹å¾ä¸çº¦æŸ
# -------------------------------
def prepare_dataset(df: pd.DataFrame):
    # ç»Ÿè®¡æ¯ä¸ªæ¨¡å¼åœ¨åŸå§‹åˆ¤æ®ä¸‹çš„åŒºé—´ï¼ˆæœºç†å…ˆéªŒï¼‰
    mode_stats = df.groupby('mode')['n_smoothed'].agg(min_mode='min', max_mode='max').reset_index()

    df = df.merge(mode_stats, on='mode', how='left')

    # ç‰¹å¾ï¼š
    #  - x0: åŸå§‹ n_smoothedï¼ˆè®©æ¨¡å‹å­¦ä¹ â€œå¾®è°ƒ/æ ¡æ­£â€è€Œéä»é›¶æ‹Ÿåˆï¼‰
    #  - x1..x4: mode çš„ one-hotï¼ˆè®©ä¸åŒæ¨¡å¼å¯èµ°åˆ°ä¸åŒå¶å­ï¼‰
    mode_onehot = pd.get_dummies(df['mode'], prefix='mode')
    X = pd.concat([df[['n_smoothed']].reset_index(drop=True), mode_onehot.reset_index(drop=True)], axis=1)

    # ç›®æ ‡ï¼šæ ¡æ­£åçš„ n_smoothedï¼ˆåˆå§‹ç”¨åŸå€¼ï¼Œè®­ç»ƒä¸­é æŸå¤±æ¨åŠ¨åˆ°æ–°ä½ç½®ï¼‰
    y = df['n_smoothed'].to_numpy(dtype=np.float64)

    # çº¦æŸï¼ˆä¾›æŸå¤±å‡½æ•°ä½¿ç”¨ï¼‰
    constraints = df[['min_mode', 'max_mode', 'mode']].to_numpy(dtype=np.float64)

    return X.to_numpy(dtype=np.float64), y, constraints, df, mode_stats


# -------------------------------
# 3) è§„èŒƒåŒ–ä¸€ä¸ªâ€œåŠ›åº¦ç³»æ•°â€ï¼ˆä½¿ä¸åŒé‡çº²å¯æ¯”ï¼‰
# -------------------------------
def _norm_positive(x: float) -> float:
    # å¹³æ»‘æ­£å‘ç¼©æ”¾åˆ° ~[0,1.5) åŒºé—´ï¼ˆå¯¹æç«¯å€¼ä¸å¤ªæ•æ„Ÿï¼‰
    return float(np.log1p(max(x, 0.0)))


# -------------------------------
# 4) è‡ªå®šä¹‰æŸå¤±ï¼šæœºç†åŒºé—´ + å…¨å±€å¼•å¯¼
# -------------------------------

def physics_constrained_loss(y_pred, dtrain):
    global TRAIN_CONSTRAINTS, TEST_CONSTRAINTS, GLOBAL_EVENT, GLOBAL_LENGTH_RATIO, GLOBAL_HEIGHT

    y_pred = np.asarray(y_pred, dtype=np.float64).flatten()
    y_true = dtrain.get_label().astype(np.float64).flatten()
    n = y_pred.size

    constraints = TRAIN_CONSTRAINTS if n == TRAIN_CONSTRAINTS.shape[0] else TEST_CONSTRAINTS
    constraints = np.asarray(constraints).reshape(-1, 3)
    n_min, n_max, mode = constraints[:, 0], constraints[:, 1], constraints[:, 2].astype(int)

    # åŸºç¡€ MSE
    grad = 2.0 * (y_pred - y_true)
    hess = np.full(n, 2.0, dtype=np.float64)

    # åŒºé—´æƒ©ç½šï¼ˆåç¦»æœºç†åŒºé—´æ—¶å¼ºçƒˆæ‹‰å›ï¼‰
    k_interval = 6.0
    mask_lower = y_pred < n_min
    mask_upper = y_pred > n_max
    grad[mask_lower] += k_interval * 2.0 * (y_pred[mask_lower] - n_min[mask_lower])
    grad[mask_upper] += k_interval * 2.0 * (y_pred[mask_upper] - n_max[mask_upper])
    hess[mask_lower] += k_interval * 2.0
    hess[mask_upper] += k_interval * 2.0

    # å…¨å±€å¼•å¯¼ï¼ˆæŒ‰æ¨¡å¼ç»™å®šâ€œæŠ¬å‡/å‹ä½â€çš„æ–¹å‘æ€§åç½®ï¼‰
    #  4 â†” event_srv_ratio æ›´å¤§ â†’ å€¾å‘æ›´é«˜
    #  3 â†” length_height_ratio æ›´å¤§ â†’ å€¾å‘æ›´é«˜
    #  2 â†” fracture_height æ›´å¤§ â†’ å€¾å‘æ›´é«˜
    #  1 â†” å€¾å‘æ›´ä½
    push_4 = +0.25 * _norm_positive(GLOBAL_EVENT)
    push_3 = +0.20 * _norm_positive(GLOBAL_LENGTH_RATIO)
    push_2 = +0.15 * _norm_positive(GLOBAL_HEIGHT)
    push_1 = -0.10  # è½»å¾®å‹ä½

    grad[mode == 4] += push_4
    grad[mode == 3] += push_3
    grad[mode == 2] += push_2
    grad[mode == 1] += push_1

    return grad, hess


# -------------------------------
# 5) è¯„ä¼°æŒ‡æ ‡ï¼šç‰©ç†å•è°ƒæ€§ï¼ˆ1<2<3<4ï¼‰
# -------------------------------

def evaluate_physics_consistency(y_pred, dtrain):
    y_pred = np.asarray(y_pred).flatten()
    constraints = TRAIN_CONSTRAINTS if y_pred.size == TRAIN_CONSTRAINTS.shape[0] else TEST_CONSTRAINTS
    mode = constraints[:, 2].astype(int)

    means = {m: float(np.mean(y_pred[mode == m])) for m in [1, 2, 3, 4]}
    score = 0.0
    score += 0.25 if means[1] < means[2] else 0.0
    score += 0.25 if means[2] < means[3] else 0.0
    score += 0.25 if means[3] < means[4] else 0.0
    score += 0.25 * (1 - np.std(list(means.values())) / (np.mean(list(means.values())) + 1e-8))
    return 'physics_score', float(score)


# -------------------------------
# 6) åŸºäºå…¨å±€çº¦æŸçš„ sample weightï¼ˆå¯é€‰åŠ å¼ºï¼‰
# -------------------------------

def build_sample_weight(df: pd.DataFrame) -> np.ndarray:
    # è®©â€œå…¨å±€çº¦æŸæ›´åŒ¹é…çš„æ¨¡å¼æ ·æœ¬â€æƒé‡å¤§ä¸€äº›
    w = np.ones(len(df), dtype=np.float64)
    w[df['mode'] == 4] *= 1.0 + 0.5 * _norm_positive(float(df['event_srv_ratio'].iloc[0]))
    w[df['mode'] == 3] *= 1.0 + 0.4 * _norm_positive(float(df['length_height_ratio'].iloc[0]))
    w[df['mode'] == 2] *= 1.0 + 0.3 * _norm_positive(float(df['fracture_height'].iloc[0]))
    # mode 1 ä¿æŒåŸºçº¿æƒé‡
    w = np.nan_to_num(w, nan=1.0, posinf=1.0, neginf=1.0)  # æ›¿æ¢æ‰ä»»ä½•å¼‚å¸¸
    w[w <= 0] = 1e-6  # ä¿è¯æœ€å°å€¼ > 0

    return w


# -------------------------------
# 7) è®­ç»ƒ
# -------------------------------

def train_model(X, y, constraints, sample_weight):
    global TRAIN_CONSTRAINTS, TEST_CONSTRAINTS

    X_train, X_test, y_train, y_test, c_train, c_test, w_train, w_test = train_test_split(
        X, y, constraints, sample_weight, test_size=0.2, random_state=42, stratify=constraints[:, 2]
    )

    TRAIN_CONSTRAINTS = c_train.reshape(-1, 3)
    TEST_CONSTRAINTS = c_test.reshape(-1, 3)

    dtrain = xgb.DMatrix(X_train, label=y_train, weight=w_train)
    dtest = xgb.DMatrix(X_test, label=y_test, weight=w_test)

    params = {
        'max_depth': 3,
        'min_child_weight': 1.0,
        'eta': 0.08,
        'subsample': 0.9,
        'colsample_bytree': 0.9,
        'reg_alpha': 0.0,
        'reg_lambda': 1.0,
        'verbosity': 1,
        'random_state': 42
    }

    print("\nğŸ“Š å¼€å§‹è®­ç»ƒæ¨¡å‹â€¦")
    model = xgb.train(
        params,
        dtrain,
        num_boost_round=400,
        obj=physics_constrained_loss,
        feval=evaluate_physics_consistency,
        evals=[(dtest, 'valid'), (dtrain, 'train')],
        early_stopping_rounds=30,
        verbose_eval=25
    )
    print(f"âœ… è®­ç»ƒå®Œæˆï¼Œæœ€ä½³è¿­ä»£: {model.best_iteration}")
    return model


# -------------------------------
# 8) ç”Ÿæˆæ ¡æ­£åŒºé—´ä¸é˜ˆå€¼
# -------------------------------

def generate_corrected_intervals(model, X, df):
    dmat = xgb.DMatrix(X)
    df = df.copy()
    df['corrected_ns'] = model.predict(dmat).astype(float)

    stats = df.groupby('mode')['corrected_ns'].agg(['min', 'max', 'mean']).reset_index()
    intervals = {int(r['mode']): [float(r['min']), float(r['max'])] for _, r in stats.iterrows()}

    # ç›¸é‚»æ¨¡å¼é˜ˆå€¼ï¼šå–ä¸Š/ä¸‹è¾¹ç•Œçš„ä¸­ç‚¹
    modes_sorted = sorted(intervals.keys())
    thresholds = {}
    for i in range(len(modes_sorted) - 1):
        m_curr, m_next = modes_sorted[i], modes_sorted[i + 1]
        thresholds[f't{i+1}'] = (intervals[m_curr][1] + intervals[m_next][0]) / 2.0

    return intervals, thresholds, df


# -------------------------------
# 9) ç‰©ç†æ€§æ£€æŸ¥ & å¯è§†åŒ–
# -------------------------------

def verify_constraints(df):
    print("\nğŸ” ç‰©ç†çº¦æŸéªŒè¯ï¼ˆæœŸæœ› 1<2<3<4ï¼‰ï¼š")
    means = df.groupby('mode')['corrected_ns'].mean().to_dict()
    print("  å„æ¨¡å¼å‡å€¼:", {int(k): float(v) for k, v in means.items()})
    seq_ok = means.get(1, 0) < means.get(2, 0) < means.get(3, 0) < means.get(4, 0)
    print("  ç»“æœ:", "âœ… ç¬¦åˆ" if seq_ok else "âŒ ä¸ç¬¦åˆ")


def visualize_results(df, thresholds):
    plt.rcParams["font.family"] = ["SimHei"]
    fig, ax = plt.subplots(figsize=(9, 5))
    colors = {1: '#FF5733', 2: '#33AA55', 3: '#3366FF', 4: '#F3C233'}
    labels = {1: 'çªç ´å±éšœ', 2: 'ç¼é«˜æ‰©å±•', 3: 'ç¼é«˜å—é™', 4: 'ç¼ç½‘æ‰©å±•'}

    for m in [1, 2, 3, 4]:
        data = df[df['mode'] == m]['corrected_ns']
        if len(data):
            ax.hist(data, bins=12, alpha=0.65, label=labels[m], color=colors[m])

    for name, val in sorted(thresholds.items(), key=lambda x: x[1]):
        ax.axvline(val, linestyle='--', alpha=0.6)
        ax.text(val, ax.get_ylim()[1]*0.95, name, rotation=90, va='top', ha='center')

    ax.set_title('æ ¡æ­£å n_smoothed åˆ†å¸ƒä¸é˜ˆå€¼')
    ax.set_xlabel('corrected_ns')
    ax.set_ylabel('æ ·æœ¬æ•°')
    ax.legend()
    plt.tight_layout()
    plt.savefig('æ ¡æ­£ç»“æœå¯è§†åŒ–.png', dpi=300)
    print("\nğŸ“ˆ å·²ä¿å­˜å›¾åƒ: æ ¡æ­£ç»“æœå¯è§†åŒ–.png")
    plt.show()


# -------------------------------
# 10) ä¸»ç¨‹åº
# -------------------------------

def main():
    # ç›´æ¥æŒ‡å®šExcelæ–‡ä»¶è·¯å¾„ï¼ˆè°ƒè¯•æ—¶ä½¿ç”¨ï¼‰
    excel_path = r"C:\Users\fy\Desktop\å‹è£‚æ–½å·¥æ•°æ®+å¾®åœ°éœ‡å‚æ•°\readresults.xlsx"

    df = load_data(excel_path)
    X, y, constraints, df, _ = prepare_dataset(df)
    sample_weight = build_sample_weight(df)

    model = train_model(X, y, constraints, sample_weight)
    intervals, thresholds, df_out = generate_corrected_intervals(model, X, df)

    print("\nğŸ“Œ æ ¡æ­£åçš„æ¨¡å¼åˆ¤åˆ«åŒºé—´:")
    name_map = {1: 'çªç ´å±éšœ', 2: 'ç¼é«˜æ‰©å±•', 3: 'ç¼é«˜å—é™', 4: 'ç¼ç½‘æ‰©å±•'}
    for m in sorted(intervals.keys()):
        lo, hi = intervals[m]
        print(f"  {name_map[m]}: [{lo:.4f}, {hi:.4f}]")

    print("\nğŸ“Œ æ¨¡å¼åˆ¤åˆ«é˜ˆå€¼:")
    for k, v in sorted(thresholds.items(), key=lambda kv: kv[1]):
        print(f"  {k}: {v:.4f}")

    verify_constraints(df_out)
    visualize_results(df_out, thresholds)

    # å¯¼å‡ºåˆ¤åˆ«å‡½æ•°
    print("\nğŸ“ æ¨¡å¼åˆ¤åˆ«å‡½æ•°ï¼š")
    print(f"""def predict_mode(n_smoothed, thresholds={ {k: float(v) for k, v in thresholds.items()} }):\n    ts = [v for _, v in sorted(thresholds.items(), key=lambda kv: kv[1])]\n    t1, t2, t3 = ts\n    if n_smoothed <= t1: return 1\n    elif n_smoothed <= t2: return 2\n    elif n_smoothed <= t3: return 3\n    else: return 4\n""")


if __name__ == '__main__':
    main()
